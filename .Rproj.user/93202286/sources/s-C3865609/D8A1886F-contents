# Linear regression (IODS, week 2)

1.
Open the data:
```{r}
lrn14 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
dim(lrn14)
```

The data is collected in Introduction to Social Statistics course, in fall 2014. The sample size is N = 166. The survey was originally conducted in Finnish. The data contains backgroud charasteristics age, gender and exam points on the course, about the students who answered the questionare. Students answer questions related on their learning approaches and their attitude towards statistics on likert scale (1 to 5). Observations where the exam points variable is zero are excluded.

Variable attitude describes the mean of questions related to students attitude towards statistics.
Variables stra, deep and surf are means of set of questions related to learning strategies. Deep describes questions how deeply student is trying to understand the statistics. Stra describes how student is organizing studying and managing time. Surf is about surface learning i.e. if student is just memorizing things without a context, or if a she doesn't find purpose for studying the topic.

Some background charasteristics are omitted from the data. The data does not contain many missing values. The meta text can be found [here][id].
 
[id]:http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-meta.txt 

2.
```{r}
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)

# create a more advanced plot matrix with ggpairs()
p <- ggpairs(lrn14, mapping = aes(col=gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))

# draw the plot
p

```

The data is collected to see how different variables affect exam points (proxy for learning). 
Points and attitude have the highest correlation on the matrix above. Points is in absolute value clearly correlated with surf and stra, but not much correlated with age or deep learning. Attitude is very highly correlated with the points, indicating that it may be very important factor for exam points. However, high correlation does not imply an causal relationship between the variables.

Age is not highly correlated with any of the variables in the sample. Also attitude has clearly lower correlations to other variables than points (0.437 for points, less than 0.2 in absolute values for other variables). 

The data contains a larger portion of females than males. On average, males have a higher value for attitude than females. Males also have on average lower values for surf (surface learning). For other variables, the distribution is quite equal for men and women. Males who partipated to the course may be more motivated to learn statistics than females.

3.
```{r}
# create an plot matrix with ggpairs()
ggpairs(lrn14, lower = list(combo = wrap("facethist", bins = 20)))
```

If the exam points is the target (dependent) variable, we should choose explanatory variables with highest correlation to exam points in absolute value. Points has highest correlation in absolute value with variables attitude (0.437), stra (0.146) and surf (0.144 in absolute value).

```{r}
# create a regression model with multiple explanatory variables
my_model2 <- lm(points ~ attitude + stra + surf, data = lrn14)

# print out a summary of the model
summary(my_model2)

```

The coefficient of stra is 0.8531, indicating a positive relationship between good learning strategies and exam points. Surf has a coefficient -0.5861, indicating that surface learning could have a negative impact to exam scores. However, explanatory variables stra and surf are not statistically significant on 10 % significance level with p-values 0.11716b and 0.46563. Thus, I remove these variables from the model. I also plot the simple model after removing these variables.


```{r}
# a scatter plot of points versus attitude
qplot(attitude, points, mapping = aes(col=gender), data = lrn14)  + geom_smooth(method = "lm")
```

From the plot we can clearly see, that attitude towards statistics is positively correlated with exam points. There may be few outliers on the bottom-right corner of the picture (a few people with weak points from exam but have a positive attitude towards learning statistics).

```{r}
# fit a linear model
my_model <- lm(points ~ attitude, data = lrn14)

# print out a summary of the model
summary(my_model)
```

Explanatory variable attitude is statistically significant on 1 % significance level (p-value 1.95e-09). 

4.
The coefficient of attitude is 3.5255 (values from summary). The coefficient describes that if the value of attitude increases by 1 (a student has more positive attitude towards studying statistics), her exam score is expected to be 3.5255 points higher. Attitude has a positive statistical relationship to the dependent variable (exam score).

Multiple R-squared has a value of 0.1906 and Adjusted R-squared has a value of 0.1856. Both of these values are low. Thus, model does not account much of the variance in the data. However, low R-squared values do not indicate that the model is not adequate and it is common to have such low values in models, that attempt to predict human behavior. The statistically significant positive relationship between explanotary variable (attitude) and dependent variable (exam points) is the main finding here. The adjusted R-squared is almost the same as on the previous model with three variables, indicating that the fit of the model remains the same.

5.
```{r}
# draw diagnostic plots using the plot() function. Choose the plots 1, 2 and 5
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
```

For using a linear regression model, one should check that error term is be normally distributed with a constant variance and expected value of zero.The error terms should not be correlated and the error term does not depend on explanatory variables.

On the first plot (residuals versus fitted), there seems to be a reasonably random spread of the points. This supports the assumption that size of the errors does not depend on explanatory variables (constant variance assumption). The second graph (Normal Q-Q-plot) shows are reasonable fit, since the points fall close within the line. Hence, it is safe to assume that the errors of the model are normally distributed.  From the third plot (residuals vs Leverage) no single observation stands out. Therefore, there are no outliers that should be removed. In conclusion, assumptions for linear regression model hold, and the model seems adequate.